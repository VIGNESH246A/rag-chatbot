# RAG-Based Customer Service Chatbot using Gemini

A production-ready Retrieval-Augmented Generation (RAG) chatbot powered by Google Gemini LLM for intelligent customer support in the smart home and electronics domain.

## ğŸ¯ Project Overview

This project implements a complete RAG pipeline that:
- Retrieves relevant information from a knowledge base using vector similarity search
- Generates contextual, accurate responses using Google Gemini LLM
- Provides multiple interfaces (Streamlit UI, CLI, API)
- Includes comprehensive evaluation metrics

## ğŸ—ï¸ Architecture

```
User Query â†’ Embedding â†’ Vector Search (FAISS) â†’ Context Retrieval 
                                                         â†“
                                           Prompt Engineering
                                                         â†“
                                            Gemini LLM Generation
                                                         â†“
                                              Response to User
```

## ğŸ“ Project Structure

```
rag_customer_chatbot/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ kb.txt                  # Knowledge base (place your data here)
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ chunks.json             # Processed chunks
â”‚   â””â”€â”€ vector_store/
â”‚       â””â”€â”€ faiss_index/            # FAISS index files
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                   # Configuration and settings
â”‚   â”œâ”€â”€ data_loader.py              # Data loading utilities
â”‚   â”œâ”€â”€ text_preprocessing.py       # Text cleaning and normalization
â”‚   â”œâ”€â”€ chunking.py                 # Document chunking logic
â”‚   â”œâ”€â”€ embeddings.py               # Gemini embedding generation
â”‚   â”œâ”€â”€ vector_store.py             # FAISS vector store management
â”‚   â”œâ”€â”€ retriever.py                # Context retrieval logic
â”‚   â”œâ”€â”€ prompt_templates.py         # Prompt engineering templates
â”‚   â”œâ”€â”€ llm_gemini.py               # Gemini LLM wrapper
â”‚   â””â”€â”€ rag_pipeline.py             # End-to-end RAG pipeline
â”‚
â”œâ”€â”€ app.py                          # Streamlit web interface
â”œâ”€â”€ cli_app.py                      # Command-line interface
â”œâ”€â”€ build_index.py                  # Index building script
â”œâ”€â”€ evaluate.py                     # Evaluation script
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                            # Environment variables (create this)
â”œâ”€â”€ .gitignore                      # Git ignore file
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd rag_customer_chatbot
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**

Create a `.env` file in the root directory:
```env
GOOGLE_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro
EMBEDDING_MODEL=models/embedding-001
```

4. **Prepare your knowledge base**

Place your knowledge base text file at:
```
data/raw/kb.txt
```

The provided knowledge base contains smart home product information, policies, and troubleshooting guides.

5. **Build the vector index**
```bash
python build_index.py
```

This will:
- Load and preprocess the knowledge base
- Chunk the documents
- Generate embeddings using Gemini
- Create and save the FAISS vector index

## ğŸ’» Usage

### Streamlit Web Interface (Recommended)

```bash
streamlit run app.py
```

Then open your browser to `http://localhost:8501`

Features:
- Interactive chat interface
- View retrieved context
- See relevance scores
- Clear conversation history
- System statistics

### Command-Line Interface

```bash
python cli_app.py
```

Commands:
- Type your question and press Enter
- `quit` or `exit` - Exit the application
- `clear` - Clear conversation history
- `stats` - Show system statistics

### Evaluation

Run the evaluation script to test the chatbot:

```bash
python evaluate.py
```

This will:
- Test the chatbot with sample questions
- Measure response accuracy
- Calculate latency metrics
- Generate a detailed evaluation report

## ğŸ“Š Evaluation Metrics

The system tracks:
- **Response Accuracy**: Keyword presence in responses
- **Contextual Relevance Score**: Similarity scores from vector search
- **Latency**: Average response time
- **User Satisfaction Score**: Based on simulated interactions
- **Precision & Recall**: For retrieval system evaluation

## ğŸ“ Skills Demonstrated

This project showcases:
- âœ… RAG pipeline implementation
- âœ… Google Gemini LLM integration
- âœ… Vector database management (FAISS)
- âœ… Natural Language Processing
- âœ… Prompt engineering
- âœ… Text similarity search
- âœ… API integration
- âœ… Full-stack application development (Streamlit)
- âœ… Performance evaluation and metrics

## ğŸ”§ Configuration

Edit `src/config.py` or `.env` file to customize:

- `CHUNK_SIZE`: Size of text chunks (default: 500)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 50)
- `TOP_K_RESULTS`: Number of chunks to retrieve (default: 3)
- `MAX_TOKENS`: Maximum response length (default: 1024)
- `TEMPERATURE`: LLM creativity (default: 0.7)

## ğŸ“ Sample Questions

Try these questions with the chatbot:

1. **Policy Questions**
   - "What is the return policy for small electronics?"
   - "How do I cancel my order?"
   - "What payment methods do you accept?"

2. **Product Information**
   - "Tell me about the Smart Refrigerator"
   - "What are the specifications of the washing machine?"
   - "How much does the Smart Thermostat cost?"

3. **Technical Support**
   - "How do I set up the Smart Thermostat?"
   - "My security camera won't connect to WiFi"
   - "How do I fix washing machine vibration?"

## ğŸ› Troubleshooting

### Index Not Found Error
```bash
# Rebuild the index
python build_index.py
```

### API Key Error
- Ensure your `.env` file contains a valid `GOOGLE_API_KEY`
- Check that the API key has access to Gemini models

### Import Errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --upgrade
```

## ğŸ“ˆ Future Enhancements

- [ ] Add support for multiple knowledge bases
- [ ] Implement user authentication
- [ ] Add conversation memory across sessions
- [ ] Integrate with external APIs (order tracking, etc.)
- [ ] Add multi-language support
- [ ] Implement feedback collection system
- [ ] Deploy as REST API
- [ ] Add A/B testing framework

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¨â€ğŸ’» Author

Vignesh A

## ğŸ™ Acknowledgments

- Google Gemini API for LLM capabilities
- FAISS library for efficient vector search
- Streamlit for the web interface
- The open-source community


